{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set the seed for reproducibility.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # If using CUDA\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  # Ensures deterministic behavior\n",
    "\n",
    "def preprocess_data(data_dir, seed=42):\n",
    "    \"\"\"Load the train/val data with fixed seed for reproducibility.\"\"\"\n",
    "\n",
    "    # Set seed before applying transformations\n",
    "    set_seed(seed)\n",
    "\n",
    "    data_transforms = {\n",
    "        'train':transforms.Compose([\n",
    "        transforms.CenterCrop((1500, 1024)),  # Center cropping\n",
    "        transforms.RandomHorizontalFlip(p=0.3),  # Random horizontal flip\n",
    "        transforms.RandomApply([transforms.RandomRotation(degrees=30)], p=0.3),  # Random rotation (-30 to +30 degrees)\n",
    "        # Randomly scales the image within a given range (scale=(0.8, 1.2), meaning 90% to 110% of the original size).\n",
    "        # Randomly crops the scaled image back to (1500, 1024), ensuring all final images are of a consistent size.\n",
    "        transforms.RandomResizedCrop((1500, 1024), scale=(0.8, 1.2)),  # Random scaling\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "        transforms.CenterCrop((1500,1024)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "    return data_transforms\n",
    "\n",
    "def save_preprocessed_images(data_dir, output_dir):\n",
    "    \"\"\"Apply preprocessing and save the images in the same parent folder.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    transform = preprocess_data(data_dir)['train']  # Use train transforms\n",
    "    \n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(data_dir, filename)\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            processed_image = transform(image)\n",
    "            \n",
    "            save_path = os.path.join(output_dir, filename)\n",
    "            processed_image = transforms.ToPILImage()(processed_image)  # Convert back to PIL for saving\n",
    "            processed_image.save(save_path)\n",
    "    \n",
    "    print(f\"Processed images saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"xxxx\"\n",
    "output_dir = r\"xxxx\"\n",
    "\n",
    "save_preprocessed_images(data_dir, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forensic-74LTp_tJ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
